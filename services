
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/

import { GoogleGenAI, GenerateContentResponse, Modality } from "@google/genai";
import { HistoricalScenario, Source } from "../types";
import { decodeBase64, decodeAudioData } from "../utils/audioUtils";

const FLASH_MODEL = 'gemini-3-flash-preview'; 
const TTS_MODEL = 'gemini-2.5-flash-preview-tts';
const IMAGE_MODEL = 'gemini-2.5-flash-image';

function extractJSON(text: string): any {
  let jsonString = text.trim().replace(/```json/gi, '').replace(/```/g, '');
  const firstOpen = jsonString.indexOf('{');
  const lastClose = jsonString.lastIndexOf('}');
  if (firstOpen === -1 || lastClose === -1) throw new Error("Error en la frecuencia temporal.");
  return JSON.parse(jsonString.substring(firstOpen, lastClose + 1));
}

export async function researchLocationAndDate(location: string, date: string): Promise<HistoricalScenario> {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const prompt = `
    ERES UN HISTORIADOR DE PRECISIÓN ABSOLUTA. Investiga: "${location}" ${date ? `en ${date}` : ""}.

    DIRECCIÓN LINGÜÍSTICA OBLIGATORIA:
    1. DETERMINA EL AÑO:
       - SI EL AÑO ES < 1521 (Época Prehispánica): El "text" DEBE ser en lengua originaria (Náhuatl, Maya, etc.) y "translation" en español.
       - SI EL AÑO ES >= 1521 (Colonia, Independencia, Revolución, Siglo XX): El "text" DEBE SER COMPLETAMENTE EN ESPAÑOL. 
       - PROHIBICIÓN: No uses Náhuatl para personajes como Benito Juárez, Porfirio Díaz, Zapata o soldados del siglo XIX. Ellos hablaban español.

    REGLAS DE GÉNERO Y VOZ:
    - Identifica a 2 protagonistas reales.
    - GÉNERO FEMENINO: Usa obligatoriamente voz 'Kore' o 'Aoede'.
    - GÉNERO MASCULINO: Usa obligatoriamente voz 'Charon' o 'Puck'.
    - ERROR CRÍTICO A EVITAR: No asignes voces femeninas a generales, soldados o líderes masculinos.

    ESTRUCTURA JSON:
    {
      "context": "Contexto histórico breve.",
      "accentProfile": "Estilo de habla.",
      "characters": [
        {
          "name": "Nombre", 
          "gender": "male|female", 
          "voice": "Charon|Puck|Kore|Aoede", 
          "visualDescription": "Retrato",
          "bio": "Bio"
        }
      ],
      "script": [
        {
          "speaker": "Nombre", 
          "text": "Diálogo (Indígena SOLO si es antes de 1521, sino ESPAÑOL)", 
          "translation": "Español actual"
        }
      ]
    }
  `;

  const response = await ai.models.generateContent({
    model: FLASH_MODEL,
    contents: prompt,
    config: { 
      tools: [{ googleSearch: {} }],
      responseMimeType: "application/json"
    }
  });

  const groundingChunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
  const sources = groundingChunks
    .filter((c: any) => c.web?.uri)
    .map((c: any) => ({ title: c.web.title || "Fuente", uri: c.web.uri }))
    .slice(0, 3);

  const data = extractJSON(response.text);
  return { ...data, sources };
}

export async function generateDialogueAudio(scenario: HistoricalScenario): Promise<AudioBuffer> {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  // Mapeo estricto basado en la decisión del modelo
  const speakerVoiceConfigs = scenario.characters.slice(0, 2).map((char, i) => {
    // FIX: Normalize to lowercase to match the VoiceName union type and avoid comparison errors
    // with capitalized strings. char.voice might contain capitalized values from the LLM.
    let vName: any = char.voice.toLowerCase();
    if (char.gender === 'female' && (vName === 'charon' || vName === 'puck')) vName = 'kore';
    if (char.gender === 'male' && (vName === 'kore' || vName === 'aoede')) vName = 'charon';
    
    // Capitalize for the API requirement (e.g., 'kore' -> 'Kore')
    const voiceName = (vName as string).charAt(0).toUpperCase() + (vName as string).slice(1).toLowerCase();
    
    return {
      speaker: `Actor_${i}`,
      voiceConfig: { prebuiltVoiceConfig: { voiceName } }
    };
  });

  let dialogueText = "";
  scenario.script.forEach(line => {
    const charIdx = scenario.characters.findIndex(c => c.name === line.speaker);
    const speakerTag = `Actor_${charIdx === -1 ? 0 : charIdx}`;
    dialogueText += `${speakerTag}: ${line.text}\n`;
  });

  const response = await ai.models.generateContent({
    model: TTS_MODEL, 
    contents: [{ parts: [{ text: dialogueText }] }],
    config: {
      responseModalities: [Modality.AUDIO], 
      speechConfig: { multiSpeakerVoiceConfig: { speakerVoiceConfigs } }
    }
  });

  const base64 = response.candidates?.[0]?.content?.parts?.find(p => p.inlineData)?.inlineData?.data;
  if (!base64) throw new Error("Audio no disponible.");
  
  const ctx = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
  const buffer = await decodeAudioData(decodeBase64(base64), ctx, 24000, 1);
  await ctx.close();
  return buffer;
}

export async function generateCharacterAvatar(description: string): Promise<string | null> {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  try {
    const response = await ai.models.generateContent({
      model: IMAGE_MODEL,
      contents: { parts: [{ text: `Cinematic historical portrait, oil painting style, hyper-realistic face: ${description}` }] }
    });
    const part = response.candidates?.[0]?.content?.parts?.find(p => p.inlineData);
    return part ? `data:image/png;base64,${part.inlineData.data}` : null;
  } catch { return null; }
}
